{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Kreditentscheidungen\n",
        "====================\n",
        "\n",
        "Fallstudie ins Deutsche übersetzt, ursprünglich hier abgerufen: [https://fairlearn.org/v0.12/auto_examples/plot_credit_loan_decisions.html#sphx-glr-auto-examples-plot-credit-loan-decisions-py](https://fairlearn.org/v0.12/auto_examples/plot_credit_loan_decisions.html#sphx-glr-auto-examples-plot-credit-loan-decisions-py)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Package Imports\n",
        "===============\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from fairlearn.metrics import (\n",
        "    MetricFrame,\n",
        "    count,\n",
        "    equalized_odds_difference,\n",
        "    false_negative_rate,\n",
        "    false_positive_rate,\n",
        "    selection_rate,\n",
        ")\n",
        "from fairlearn.postprocessing import ThresholdOptimizer\n",
        "from fairlearn.reductions import EqualizedOdds, ExponentiatedGradient\n",
        "\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "rand_seed = 1234\n",
        "np.random.seed(rand_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fairness-Überlegungen bei Kreditentscheidungen\n",
        "============================================\n",
        "\n",
        "Fairness und Kreditvergabe in den USA\n",
        "-------------------------------------\n",
        "\n",
        "2019 erhielt Apple in den sozialen Medien Kritik, nachdem das neu eingeführte *Apple Card*-Produkt scheinbar Männern höhere Kreditlimits im Vergleich zu Frauen angeboten hat `nedlund2019apple`{.interpreted-text role=\"footcite\"}. In mehreren Fällen stellten verheiratete Paare fest, dass der Ehemann ein Kreditlimit erhielt, das 10-20-mal höher war als das der Ehefrau, selbst wenn das Paar gemeinsame Vermögenswerte hatte.\n",
        "\n",
        "Aus regulatorischer Sicht unterliegen Finanzinstitute, die innerhalb der Vereinigten Staaten tätig sind, *gesetzlichen Vorschriften*, die Diskriminierung aufgrund von [Rasse, Geschlecht oder anderen geschützten Klassen :footcite:`uscode2011title15chapter41subchapteriv]{.title-ref} verbieten. Mit der zunehmenden Verbreitung automatisierter Entscheidungssysteme im Bereich der Finanzkreditvergabe haben Experten Bedenken geäußert, ob diese Systeme bestehende Ungleichheiten in der Finanzkreditvergabe verschärfen könnten.\n",
        "\n",
        "Obwohl die beiden Konzepte miteinander verflochten sind, ist algorithmische Fairness nicht dasselbe wie Antidiskriminierungsgesetz. Ein KI-System kann mit Antidiskriminierungsgesetzen konform sein und dennoch Fairness-bezogene Bedenken aufweisen. Andererseits können einige Fairness-Interventionen nach Antidiskriminierungsgesetzen illegal sein. :footcite:`Xiang2019legalcompatibility`{.interpreted-text role=\"cts\"} diskutieren die Kompatibilitäten und Trennungen zwischen Antidiskriminierungsgesetzen und algorithmischen Fairness-Konzepten. In dieser Fallstudie konzentrieren wir uns auf Fairness im Finanzdienstleistungsbereich anstelle der Einhaltung finanzieller Antidiskriminierungsvorschriften.\n",
        "\n",
        "Ernst & Young (EY) Fallstudie\n",
        "============================\n",
        "\n",
        "In dieser Fallstudie zielen wir darauf ab, die Arbeit in einem Whitepaper `dudik2020assessing`{.interpreted-text role=\"footcite\"}, mitverfasst von *Microsoft* und *EY*, zur Minderung geschlechtsbezogener Leistungsunterschiede bei Finanzkreditentscheidungen zu replizieren. In ihrer Analyse zeigten Microsoft und EY, wie Fairlearn verwendet werden kann, um Unfairness im Kreditentscheidungsprozess zu messen und zu mindern.\n",
        "\n",
        "Mit einem Datensatz von Kreditausgangsergebnissen (ob eine Person mit einem Kredit ausgefallen ist) trainieren wir ein Fairness-unbewusstes Modell, um die Wahrscheinlichkeit vorherzusagen, dass eine Person bei einem bestimmten Kredit ausfällt. Wir verwenden das Fairlearn-Toolkit, um die Fairness unseres Modells anhand mehrerer Metriken zu bewerten. Schließlich führen wir zwei Unfairness-Minderungsstrategien an unserem Modell durch und vergleichen die Ergebnisse mit unserem ursprünglichen Modell.\n",
        "\n",
        "Da der im Whitepaper verwendete Datensatz nicht öffentlich verfügbar ist, werden wir ein semi-synthetisches Merkmal in einen bestehenden öffentlich verfügbaren Datensatz einführen, um die im ursprünglichen Datensatz gefundenen Ergebnisunterschiede zu replizieren.\n",
        "\n",
        "Kreditentscheidungsdatensatz\n",
        "---------------------------\n",
        "\n",
        "Wie bereits erwähnt, werden wir den ursprünglichen Kreditausgangsdaten nicht verwenden können und stattdessen mit einem öffentlich verfügbaren Datensatz von Kreditkartenausfällen in Taiwan aus dem Jahr 2005 arbeiten. Dieser Datensatz stellt binäre Kreditkartenausgangsergebnisse für 30.000 Antragsteller mit Informationen zu der Zahlungshistorie und den Rechnungsstellungen eines Antragstellers über einen Zeitraum von sechs Monaten von April 2005 bis September 2005 sowie demografischen Informationen wie *Geschlecht*, *Alter*, *Familienstand* und *Bildungsniveau* des Antragstellers dar. Eine vollständige Zusammenfassung der Merkmale finden Sie unten:\n",
        "\n",
        "| Merkmale                                                                   | Beschreibung                                       |\n",
        "| --------------------------------------------------------------------------| --------------------------------------------------|\n",
        "| sex, education, marriage, age                                              | demografische Merkmale                             |\n",
        "| pay\\_0, pay\\_2, pay\\_3, pay\\_4, pay\\_5, pay\\_6                             | Rückzahlungsstatus (ordinal)                       |\n",
        "| bill\\_amt1, bill\\_amt2, bill\\_amt3, bill\\_amt4, bill\\_amt5, bill\\_amt\\_6   | Rechnungsbetrag (Taiwan-Dollar)                    |\n",
        "| pay\\_amt1, pay\\_amt2, pay\\_amt3, pay\\_amt4, pay\\_amt5, pay\\_amt6           | vorheriger Rechnungsbetrag (Taiwan-Dollar)         |\n",
        "| default payment next month                                                 | Ausfalldaten (1 = JA, 0 = NEIN)                    |\n",
        "\n",
        "Stellen Sie sich vor, wir sind ein Datenwissenschaftler bei einem Finanzinstitut, der damit beauftragt ist, ein Klassifikationsmodell zu entwickeln, das vorhersagt, ob ein Antragsteller bei einem Privatkredit ausfallen wird. Eine positive Vorhersage des Modells bedeutet, dass der Antragsteller bei dem Kredit ausfallen würde. *Bei einem Kredit ausfallen* bedeutet, dass der Kunde innerhalb eines 30-Tage-Fensters keine Zahlungen leistet und der Kreditgeber rechtliche Schritte gegen den Kunden einleiten kann.\n",
        "\n",
        "Obwohl wir keinen Datensatz mit Kredit-Ausfallhistorie haben, verfügen wir über diesen Datensatz mit Kreditkartenzahlungshistorie. Wir nehmen an, dass Kunden, die monatliche Kreditkartenzahlungen pünktlich leisten, als kreditwürdiger gelten und daher weniger wahrscheinlich bei einem Privatkredit ausfallen.\n",
        "\n",
        "**Entscheidungspunkt: Aufgabenstellung**\n",
        "\n",
        "-   **Zahlungsausfall bei einer Kreditkartenzahlung** kann als Proxy dafür angesehen werden, dass ein Antragsteller möglicherweise kein guter andidat für einen Privatkredit ist.\n",
        "-   Da die meisten Kunden bei ihren Kreditkartenzahlungen nicht ausfallen, müssen wir dieses Klassenungleichgewicht während unseres Modellierungsprozesses berücksichtigen.\n",
        "\n",
        "Da die Daten im Speicher gelesen werden, ändern wir die Spalte `PAY_0` in `PAY_1`, um die Benennung konsistenter mit den anderen Spalten zu gestalten. Darüber hinaus wird die Zielvariable `default payment next month` zu `default` geändert, um die Verbosität zu reduzieren.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"\n",
        "dataset = (\n",
        "    pd.read_excel(io=data_url, header=1)\n",
        "    .drop(columns=[\"ID\"])\n",
        "    .rename(columns={\"PAY_0\": \"PAY_1\", \"default payment next month\": \"default\"})\n",
        ")\n",
        "\n",
        "dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aus der [Datensatzbeschreibung\n",
        ":footcite:`yeh2009comparisons]{.title-ref}, sehen wir, dass es drei\n",
        "kategorische Merkmale gibt:\n",
        "\n",
        "-   `SEX`: Geschlecht des Antragstellers (als binäres Merkmal)\n",
        "-   `EDUCATION`: Höchstes Bildungsniveau, das vom Antragsteller erreicht wurde.\n",
        "-   `MARRIAGE`: Familienstand des Antragstellers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "categorical_features = [\"SEX\", \"EDUCATION\", \"MARRIAGE\"]\n",
        "\n",
        "for col_name in categorical_features:\n",
        "    dataset[col_name] = dataset[col_name].astype(\"category\")\n",
        "\n",
        "Y, A = dataset.loc[:, \"default\"], dataset.loc[:, \"SEX\"]\n",
        "X = pd.get_dummies(dataset.drop(columns=[\"default\", \"SEX\"]))\n",
        "\n",
        "A_str = A.map({1: \"male\", 2: \"female\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Datensatz-Ungleichgewichte\n",
        "==========================\n",
        "\n",
        "Bevor wir mit dem Training eines Klassifikationsmodells beginnen, möchten wir den Datensatz auf Eigenschaften untersuchen, die später im Modellierungsprozess zu fairness-bezogenen Schäden führen könnten. Insbesondere werden wir uns auf die Verteilung des sensiblen Merkmals `SEX` und des Ziellabels `default` konzentrieren.\n",
        "\n",
        "Im Rahmen einer explorativen Datenanalyse lassen Sie uns die Verteilung unseres sensiblen Merkmals `SEX` untersuchen. Wir sehen, dass 60% der Kreditnehmer als [weiblich]{.title-ref} und 40% als [männlich]{.title-ref} gekennzeichnet wurden, sodass wir uns keine Sorgen über ein Ungleichgewicht in diesem Merkmal machen müssen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "A_str.value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, let\\'s explore the distribution of the *loan default rate* `Y`. We\n",
        "see that around 78% of individuals in the dataset do not default on\n",
        "their credit loan. While the target label does not display extreme\n",
        "imbalance, we will need to account for this imbalance in our modeling\n",
        "section. As opposed to the *sensitive feature* `SEX`, an imbalance in\n",
        "the target label may result in a classifier that over-optimizes for the\n",
        "majority class. For example, a classifier that predicts an applicant\n",
        "will not default would achieve an accuracy of 78%, so we will use the\n",
        "`balanced_accuracy` score as our evaluation metric to counteract the\n",
        "label imbalance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Y.value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fügen Sie synthetisches Rauschen hinzu, das mit dem Ergebnis und dem Geschlecht zusammenhängt\n",
        "==============================================================================================\n",
        "\n",
        "Für diese Fallstudie fügen wir ein synthetisches Merkmal `Interest` hinzu, das eine Korrelation zwischen dem `SEX`-Label eines Antragstellers und dem `default`-Ergebnis einführt. Der Zweck dieses Merkmals besteht darin, Ergebnisunterschiede, die im ursprünglichen Datensatz vorhanden sind, zu replizieren. Wir können dieses `Interest`-Merkmal als den *Zinssatz* für den Antragsteller betrachten. Wenn der Antragsteller eine Geschichte von Ausfällen bei Kreditkartenzahlungen hat, wird die Bank dem Antragsteller einen höheren Zinssatz anbieten. Wir nehmen auch an, dass, weil Banken historisch gesehen hauptsächlich an Männer verliehen haben, es für diese Antragsteller weniger Unsicherheit (oder Varianz) im *Zinssatz* gibt.\n",
        "\n",
        "Um die oben genannten Überlegungen widerzuspiegeln, wird das `Interest`-Merkmal aus einer *Gaußschen Verteilung* mit den folgenden Kriterien gezogen:\n",
        "\n",
        "-   Wenn *Männlich*, ziehe `Interest` aus\n",
        "    $\\mathcal{N}(2 \\cdot \\text{Default}, 1)$\n",
        "-   Wenn *Weiblich*, ziehe `Interest` aus\n",
        "    $\\mathcal{N}(2 \\cdot \\text{Default}, 2)$\n",
        "\n",
        "Dieses Merkmal wird aus einer *Gaußschen Verteilung* zur rechnerischen Einfachheit gezogen.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X.loc[:, \"Interest\"] = np.random.normal(loc=2 * Y, scale=A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Überprüfen Sie, ob dies zu Unterschieden im naiven Modell führt\n",
        "===================================================\n",
        "    \n",
        "Nachdem wir unser synthetisches Merkmal erstellt haben, lassen Sie uns überprüfen, wie dieses neue Merkmal mit unserem *sensitive_feature* `Sex` und unserem Ziellabel `default` interagiert. Wir sehen, dass für beide Geschlechter das Merkmal `Interest` höher ist bei Personen, die ihren Kredit ausgefallen haben.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, (ax_1, ax_2) = plt.subplots(ncols=2, figsize=(10, 4), sharex=True, sharey=True)\n",
        "X[\"Interest\"][(A == 1) & (Y == 0)].plot(\n",
        "    kind=\"kde\", label=\"Payment on Time\", ax=ax_1, title=\"INTEREST for Men\"\n",
        ")\n",
        "X[\"Interest\"][(A == 1) & (Y == 1)].plot(kind=\"kde\", label=\"Payment Default\", ax=ax_1)\n",
        "X[\"Interest\"][(A == 2) & (Y == 0)].plot(\n",
        "    kind=\"kde\",\n",
        "    label=\"Payment on Time\",\n",
        "    ax=ax_2,\n",
        "    legend=True,\n",
        "    title=\"INTEREST for Women\",\n",
        ")\n",
        "X[\"Interest\"][(A == 2) & (Y == 1)].plot(\n",
        "    kind=\"kde\", label=\"Payment Default\", ax=ax_2, legend=True\n",
        ").legend(bbox_to_anchor=(1.6, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training eines ersten Modells\n",
        "=============================\n",
        "\n",
        "In diesem Abschnitt werden wir ein Fairness-unbewusstes Modell auf den Trainingsdaten trainieren. Aufgrund der Ungleichgewichte im Datensatz werden wir jedoch zunächst die Trainingsdaten neu sampeln, um einen neuen ausgeglichenen Trainingsdatensatz zu erstellen.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def resample_training_data(X_train, Y_train, A_train):\n",
        "    \"\"\"Down-sample the majority class in the training dataset to produce a\n",
        "    balanced dataset with a 50/50 split in the predictive labels.\n",
        "\n",
        "    Parameters:\n",
        "    X_train: The training split of the features\n",
        "    Y_train: The training split of the target labels\n",
        "    A_train: The training split of the sensitive features\n",
        "\n",
        "    Returns:\n",
        "    Tuple of X_train, Y_train, A_train where each dataset has been re-balanced.\n",
        "    \"\"\"\n",
        "    negative_ids = Y_train[Y_train == 0].index\n",
        "    positive_ids = Y_train[Y_train == 1].index\n",
        "    balanced_ids = positive_ids.union(np.random.choice(a=negative_ids, size=len(positive_ids)))\n",
        "\n",
        "    X_train = X_train.loc[balanced_ids, :]\n",
        "    Y_train = Y_train.loc[balanced_ids]\n",
        "    A_train = A_train.loc[balanced_ids]\n",
        "    return X_train, Y_train, A_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test, A_train, A_test = train_test_split(\n",
        "    X, Y, A_str, test_size=0.35, stratify=Y\n",
        ")\n",
        "\n",
        "X_train, y_train, A_train = resample_training_data(X_train, y_train, A_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "An diesem Punkt werden wir einen *radient-boosted tree classifier* mithilfe des `lightgbm`-Pakets auf dem ausgeglichenen Trainingsdatensatz trainieren. Bei der Bewertung des Modells werden wir den unausgeglichenen Testdatensatz verwenden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lgb_params = {\n",
        "    \"objective\": \"binary\",\n",
        "    \"metric\": \"auc\",\n",
        "    \"learning_rate\": 0.03,\n",
        "    \"num_leaves\": 10,\n",
        "    \"max_depth\": 3,\n",
        "    \"random_state\": rand_seed,\n",
        "    \"n_jobs\": 1,\n",
        "    \"verbose\": -1,\n",
        "}\n",
        "\n",
        "estimator = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocessing\", StandardScaler()),\n",
        "        (\"classifier\", lgb.LGBMClassifier(**lgb_params)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "estimator.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wir berechnen die *binary prediction* und die *prediciton probabilities* für die Testdaten."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Y_pred_proba = estimator.predict_proba(X_test)[:, 1]\n",
        "Y_pred = estimator.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Am *ROC Score* können wir sehen, dass das Modell anscheinend zwischen *true positives* und *false positives* zu unterscheiden vermag. Das war auch so zu erwarten, denn `INTEREST` ist ein stark diskrimminierendes Feature für die Klassifikation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "roc_auc_score(y_test, Y_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merkmalswichtigkeit des unveränderten Klassifikators\n",
        "====================================================\n",
        "    \n",
        "Als Modellvalidierungsprüfung lassen Sie uns die Merkmalswichtigkeiten unseres Klassifikators untersuchen. Wie erwartet hat unser synthetisches Merkmal `INTEREST` die höchste Merkmalswichtigkeit, da es konstruktionsbedingt stark mit der Zielvariablen korreliert.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lgb.plot_importance(\n",
        "    estimator.named_steps[\"classifier\"],\n",
        "    height=0.6,\n",
        "    title=\"Feature Importance\",\n",
        "    importance_type=\"gain\",\n",
        "    max_num_features=15,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fairness-Bewertung des unveränderten Modells\n",
        "===========================================\n",
        "\n",
        "Nachdem wir unser erstes Fairness-unbewusstes Modell trainiert haben, führen wir nun unsere Fairness-Bewertung für dieses Modell durch. Bei der Durchführung einer Fairness-Bewertung gibt es drei Hauptschritte, die wir durchführen möchten:\n",
        "\n",
        "1.  Identifizieren, wer geschädigt wird.\n",
        "2.  Identifizieren der Arten von Schäden, die wir erwarten.\n",
        "3.  Definieren von Fairness-Metriken basierend auf den erwarteten Schäden.\n",
        "\n",
        "Wer wird geschädigt?\n",
        "---------------------\n",
        "\n",
        "Basierend auf dem Vorfall mit der *Apple* Kreditkarte, der zu Beginn dieses Notebooks erwähnt wurde, glauben wir, dass das Modell fälschlicherweise vorhersagen könnte, dass Frauen bei der Kreditvergabe ausfallen werden. Das System könnte Frauen unfairerweise weniger Kredite zuweisen und Männern übermäßig Kredite gewähren.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Arten von erlebten Schäden\n",
        "==========================\n",
        "\n",
        "Beim Diskutieren von Fairness in KI-Systemen ist der erste Schritt zu verstehen, welche Arten von Schäden wir erwarten, dass das System erzeugen könnte. Mit der `Schadenstaxonomie im Fairlearn Benutzerhandbuch <types_of_harms>`{.interpreted-text role=\"ref\"}, erwarten wir, dass dieses System *Zuweisungsschäden* erzeugt. Darüber hinaus erwarten wir auch die langfristigen Auswirkungen auf die Kreditwürdigkeit einer Person, wenn eine Person nicht in der Lage ist, einen erhaltenen Kredit zurückzuzahlen oder wenn sie für einen Kreditantrag abgelehnt wird. Ein *Zuweisungsschaden* tritt auf, wenn ein KI-System Ressourcen, Möglichkeiten oder Informationen erweitert oder zurückhält. In diesem Szenario erweitert oder hält das KI-System finanzielle Ressourcen von Individuen zurück oder verteilt sie aus. Ein Rückblick auf historische Vorfälle zeigt, dass diese Art von automatisierten Kreditentscheidungsystemen möglicherweise unfair basierend auf dem Geschlecht diskriminieren.\n",
        "\n",
        "**Negative Auswirkungen auf die Kreditwürdigkeit**\n",
        "\n",
        "Eine sekundäre Schadensart, die in Kreditentscheidungen etwas einzigartig ist, sind die langfristigen Auswirkungen auf die Kreditwürdigkeit einer Person. In den Vereinigten Staaten ist eine [FICO-Kreditwürdigkeitsscore](https://www.investopedia.com/terms/c/credit_score.asp) eine Zahl zwischen 300 und 850, die die *Kreditwürdigkeit* eines Kunden darstellt. Die Kreditwürdigkeit eines Antragstellers wird von vielen Finanzinstituten für Kreditentscheidungen verwendet. Die Kreditwürdigkeit eines Antragstellers steigt in der Regel nach einer erfolgreichen Rückzahlung eines Kredits und sinkt, wenn der Antragsteller den Kredit nicht zurückzahlt.\n",
        "\n",
        "Bei der Beantragung eines Kredits gibt es drei Hauptausgänge:\n",
        "\n",
        "1.  Die Person erhält den Kredit und zahlt den Kredit zurück. In diesem Szenario erwarten wir, dass die Kreditwürdigkeit der Person als Ergebnis der erfolgreichen Rückzahlung des Kredits steigt.\n",
        "2.  Die Person erhält den Kredit, fällt aber beim Kredit aus. In diesem Szenario wird die Kreditwürdigkeit der Person aufgrund der Nichtzahlung des Kredits drastisch sinken. Im Modellierungsprozess ist dieses Ergebnis mit einem **falschen Negativ** verbunden (das Modell sagt voraus, dass die Person den Kredit zurückzahlen wird, die Person ist jedoch nicht erfolgreich).\n",
        "3.  In bestimmten Ländern, wie den Vereinigten Staaten, erhält eine Person nach einer *harten Anfrage* zu ihrer Kredithistorie einen kleinen Rückgang (bis zu fünf Punkte) ihrer Kreditwürdigkeit. Wenn der Antragsteller einen Kredit beantragt, aber keinen erhält, wird der kleine Rückgang seiner Kreditwürdigkeit seine Fähigkeit beeinträchtigen, sich erfolgreich für einen zukünftigen Kredit zu bewerben. Im Modellierungsprozess ist dieses Ergebnis mit der **Auswahlrate** verbunden (der Anteil der positiven Vorhersagen, die vom Modell ausgegeben werden).\n",
        "\n",
        "**Verhinderung von Vermögensakkumulation**\n",
        "\n",
        "Eine weitere Schadensart, die wir in diesem Szenario erwarten, sind die langfristigen Auswirkungen der *Ablehnung von Krediten an Antragsteller, die den Kredit erfolgreich zurückgezahlt hätten*. Durch die Erhaltung eines Kredits kann ein Antragsteller ein Haus kaufen, ein Unternehmen gründen oder eine andere wirtschaftliche Aktivität ausüben, die er sonst nicht tun könnte. Diese Ergebnisse sind mit **falschen Positivfehlern** verbunden, bei denen das Modell vorhersagt, dass ein Antragsteller beim Kredit ausfallen wird, die Person den Kredit jedoch erfolgreich zurückgezahlt hätte. In den Vereinigten Staaten hat die Praxis des Redlining `peyton2020redlining`{.interpreted-text role=\"footcite\"}, bei der Hypothekarkredite und andere Finanzdienstleistungen überwiegend schwarzen oder anderen Minderheitengemeinschaften verweigert werden, zu einer erheblichen rassischen Vermögenslücke zwischen weißen und schwarzen Amerikanern geführt. Obwohl die Praxis des Redlining 1968 mit dem *Fair Housing Act* verboten wurde, spiegeln die langfristigen Auswirkungen dieser Praktiken `jan2018redlining`{.interpreted-text role=\"footcite\"} den Mangel an wirtschaftlicher Investition in schwarze Gemeinschaften wider, und schwarze Antragsteller werden im Vergleich zu weißen Amerikanern häufiger Kredite verweigert.\n",
        "\n",
        "Fairness-Metriken basierend auf Schäden definieren\n",
        "---------------------------------------------------\n",
        "\n",
        "Nachdem wir die relevanten Schäden identifiziert haben, die wir erwarten, dass die Nutzer erleben, können wir unsere Fairness-Metriken definieren. Zusätzlich zu den Metriken werden wir die Unsicherheit um jede Metrik mithilfe von *benutzerdefinierten Funktionen* berechnen, um den *Standardfehler* für jede Metrik auf dem $\\alpha=0.95$ Konfidenzniveau zu berechnen.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def compute_error_metric(metric_value, sample_size):\n",
        "    \"\"\"Compute standard error of a given metric based on the assumption of\n",
        "    normal distribution.\n",
        "\n",
        "    Parameters:\n",
        "    metric_value: Value of the metric\n",
        "    sample_size: Number of data points associated with the metric\n",
        "\n",
        "    Returns:\n",
        "    The standard error of the metric\n",
        "    \"\"\"\n",
        "    metric_value = metric_value / sample_size\n",
        "    return 1.96 * np.sqrt(metric_value * (1.0 - metric_value)) / np.sqrt(sample_size)\n",
        "\n",
        "\n",
        "def false_positive_error(y_true, y_pred):\n",
        "    \"\"\"Compute the standard error for the false positive rate estimate.\"\"\"\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return compute_error_metric(fp, tn + fp)\n",
        "\n",
        "\n",
        "def false_negative_error(y_true, y_pred):\n",
        "    \"\"\"Compute the standard error for the false negative rate estimate.\"\"\"\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return compute_error_metric(fn, fn + tp)\n",
        "\n",
        "\n",
        "def balanced_accuracy_error(y_true, y_pred):\n",
        "    \"\"\"Compute the standard error for the balanced accuracy estimate.\"\"\"\n",
        "    fpr_error, fnr_error = false_positive_error(y_true, y_pred), false_negative_error(\n",
        "        y_true, y_pred\n",
        "    )\n",
        "    return np.sqrt(fnr_error**2 + fpr_error**2) / 2\n",
        "\n",
        "\n",
        "fairness_metrics = {\n",
        "    \"count\": count,\n",
        "    \"balanced_accuracy\": balanced_accuracy_score,\n",
        "    \"balanced_acc_error\": balanced_accuracy_error,\n",
        "    \"selection_rate\": selection_rate,\n",
        "    \"false_positive_rate\": false_positive_rate,\n",
        "    \"false_positive_error\": false_positive_error,\n",
        "    \"false_negative_rate\": false_negative_rate,\n",
        "    \"false_negative_error\": false_negative_error,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wähle eine Selektion an Metriken aus, um Information-Overload zu vermeiden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "metrics_to_report = [\n",
        "    \"balanced_accuracy\",\n",
        "    \"false_positive_rate\",\n",
        "    \"false_negative_rate\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Um die aufgeschlüsselten Leistungsmetriken zu berechnen, werden wir das `MetricFrame`-Objekt innerhalb der Fairlearn-Bibliothek verwenden. Wir werden unser Dictionary von Metriken `fairness_metrics` sowie unsere Testlabels `y_test` und Testvorhersagen `Y_pred` übergeben. Zusätzlich übergeben wir die *sensitive_features* `A_test`, um unsere Modellergebnisse aufzuschlüsseln.\n",
        "\n",
        "Instanziieren des MetricFrame für das unveränderte Modell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "metricframe_unmitigated = MetricFrame(\n",
        "    metrics=fairness_metrics,\n",
        "    y_true=y_test,\n",
        "    y_pred=Y_pred,\n",
        "    sensitive_features=A_test,\n",
        ")\n",
        "\n",
        "metricframe_unmitigated.by_group[metrics_to_report]\n",
        "\n",
        "metricframe_unmitigated.difference()[metrics_to_report]\n",
        "\n",
        "metricframe_unmitigated.overall[metrics_to_report]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_group_metrics_with_error_bars(metricframe, metric, error_name):\n",
        "    \"\"\"Plot the disaggregated metric for each group with an associated\n",
        "    error bar. Both metric and the error bar are provided as columns in the\n",
        "    provided MetricFrame.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    metricframe : MetricFrame\n",
        "        The MetricFrame containing the metrics and their associated\n",
        "        uncertainty quantification.\n",
        "    metric : str\n",
        "        The metric to plot\n",
        "    error_name : str\n",
        "        The associated standard error for each metric in metric\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Matplotlib Plot of point estimates with error bars\n",
        "    \"\"\"\n",
        "    grouped_metrics = metricframe.by_group\n",
        "    point_estimates = grouped_metrics[metric]\n",
        "    error_bars = grouped_metrics[error_name]\n",
        "    lower_bounds = point_estimates - error_bars\n",
        "    upper_bounds = point_estimates + error_bars\n",
        "\n",
        "    x_axis_names = [str(name) for name in error_bars.index.to_flat_index().tolist()]\n",
        "    plt.vlines(\n",
        "        x_axis_names,\n",
        "        lower_bounds,\n",
        "        upper_bounds,\n",
        "        linestyles=\"dashed\",\n",
        "        alpha=0.45,\n",
        "    )\n",
        "    plt.scatter(x_axis_names, point_estimates, s=25)\n",
        "    plt.xticks(rotation=0)\n",
        "    y_start, y_end = np.round(min(lower_bounds), decimals=2), np.round(\n",
        "        max(upper_bounds), decimals=2\n",
        "    )\n",
        "    plt.yticks(np.arange(y_start, y_end, 0.05))\n",
        "    plt.ylabel(metric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_group_metrics_with_error_bars(\n",
        "    metricframe_unmitigated, \"false_positive_rate\", \"false_positive_error\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_group_metrics_with_error_bars(\n",
        "    metricframe_unmitigated, \"false_negative_rate\", \"false_negative_error\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "metricframe_unmitigated.by_group[metrics_to_report].plot.bar(\n",
        "    subplots=True, layout=[1, 3], figsize=[12, 4], legend=None, rot=0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Schließlich berechnen wir die `equalized_odds_difference` für dieses unveränderte Modell. Die `equalized_odds_difference` ist das Maximum der `false_positive_rate_difference` und der `false_negative_rate_difference`. In unserem Kreditvergabe-Kontext führen sowohl *false_negative_rate_disparities* als auch *false_positive_rate_disparities* zu fairness-bezogenen Schäden. Daher versuchen wir, beide Metriken zu minimieren, indem wir die `equalized_odds_difference` minimieren."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "balanced_accuracy_unmitigated = balanced_accuracy_score(y_test, Y_pred)\n",
        "equalized_odds_unmitigated = equalized_odds_difference(y_test, Y_pred, sensitive_features=A_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Eine wichtige Annahme hier ist, dass wir davon ausgehen, dass *falsche Positive* und *falsche Negative* für jede Gruppe gleichermaßen nachteilige Kosten haben. In der Praxis würden wir einen Gewichtungsmechanismus entwickeln, um jedem *falschen Negativ* und *falschen Positiv* Ereignis ein Gewicht zuzuweisen.\n",
        "\n",
        "Minderung von Unfairness in ML-Modellen\n",
        "======================================\n",
        "\n",
        "Im vorherigen Abschnitt haben wir Unterschiede in der Leistung des Modells in Bezug auf `SEX` identifiziert. Insbesondere haben wir festgestellt, dass das Modell eine deutlich höhere `false_negative_rate` und `false_positive_rate` für die als `female` gekennzeichneten Antragsteller im Vergleich zu den als `male` gekennzeichneten produziert. Im Kontext des Kreditentscheidungs-Szenarios bedeutet dies, dass das Modell Kredite für *Frauen*, die den Kredit hätten zurückzahlen können, unterzuweisen scheint, aber Kredite für *Frauen*, die ihren Kredit ausfallen lassen, zu überzuweisen scheint.\n",
        "\n",
        "In diesem Abschnitt werden wir Strategien zur Minderung der Leistungsunterschiede, die wir in unserem unveränderten Modell gefunden haben, diskutieren. Wir werden zwei verschiedene Minderungsstrategien anwenden:\n",
        "\n",
        "-   *Postprocessing*: Beim Postprocessing-Ansatz werden die Ausgaben eines trainierten Klassifikators transformiert, um ein bestimmtes Fairness-Kriterium zu erfüllen.\n",
        "\n",
        "-   *Reductions*: Beim Reductions-Ansatz nehmen wir eine Modellklasse und erstellen iterativ eine Folge von Modellen, die eine bestimmte Fairness-Beschränkung optimieren. Im Vergleich zum *Postprocessing*-Ansatz wird die Fairness-Beschränkung während des Modelltrainings erfüllt, anstatt danach.\n",
        "\n",
        "Postprocessing-Minderungen: ThresholdOptimizer\n",
        "-----------------------------------------------\n",
        "\n",
        "Im Fairlearn-Paket wird die *Postprocessing*-Minderung durch den `ThresholdOptimizer`-Algorithmus angeboten, gemäß :footcite`hardt2016equality`{.interpreted-text role=\"cts\"}. Der `ThresholdOptimizer` nimmt ein bestehendes (möglicherweise vortrainiertes) Machine Learning-Modell, dessen Vorhersagen als Bewertungsfunktion dienen, um separate Schwellenwerte für jede *sensitive_features* Gruppe zu identifizieren. Der `ThresholdOptimizer` optimiert eine spezifizierte Zielmetrik (in unserem Fall `balanced_accuracy`) unter Einhaltung einer bestimmten Fairness-Beschränkung ([equalized_odds]{.title-ref}), was zu einer geschwellenwerteten Version des zugrunde liegenden Machine Learning-Modells führt.\n",
        "\n",
        "Um unseren `ThresholdOptimizer` zu instanziieren, müssen wir unsere Fairness-Beschränkung als Modellparameter spezifizieren. Da sowohl die Unterschiede in der `false_negative_rate` als auch in der `false_positive_rate` in unserem Szenario zu realen Schäden führen, werden wir versuchen, die `equalized_odds`-Differenz als unsere *Fairness-Beschränkung* zu minimieren.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "postprocess_est = ThresholdOptimizer(\n",
        "    estimator=estimator,\n",
        "    constraints=\"equalized_odds\",  # Optimize FPR and FNR simultaneously\n",
        "    objective=\"balanced_accuracy_score\",\n",
        "    prefit=True,\n",
        "    predict_method=\"predict_proba\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Eine wesentliche Einschränkung des `ThresholdOptimizer` ist die Notwendigkeit sensibler Merkmale während des Trainings- und Vorhersagezeitpunkts. Wenn wir während der Vorhersagezeit keinen Zugriff auf die `sensitive_features` haben, können wir den `ThresholdOptimizer` nicht verwenden.\n",
        "\n",
        "Wir übergeben `A_train` an die `fit`-Funktion mit dem Parameter `sensitive_features`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "postprocess_est.fit(X=X_train, y=y_train, sensitive_features=A_train)\n",
        "\n",
        "postprocess_pred = postprocess_est.predict(X_test, sensitive_features=A_test)\n",
        "\n",
        "postprocess_pred_proba = postprocess_est._pmf_predict(X_test, sensitive_features=A_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fairness Beurteilung des Post-processing Models\n",
        "===========================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def compare_metricframe_results(mframe_1, mframe_2, metrics, names):\n",
        "    \"\"\"Concatenate the results of two MetricFrames along a subset of metrics.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    mframe_1: First MetricFrame for comparison\n",
        "    mframe_2: Second MetricFrame for comparison\n",
        "    metrics: The subset of metrics for comparison\n",
        "    names: The names of the selected metrics\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    MetricFrame : MetricFrame\n",
        "        The concatenation of the two MetricFrames, restricted to the metrics\n",
        "        specified.\n",
        "\n",
        "    \"\"\"\n",
        "    return pd.concat(\n",
        "        [mframe_1.by_group[metrics], mframe_2.by_group[metrics]],\n",
        "        keys=names,\n",
        "        axis=1,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bal_acc_postprocess = balanced_accuracy_score(y_test, postprocess_pred)\n",
        "eq_odds_postprocess = equalized_odds_difference(\n",
        "    y_test, postprocess_pred, sensitive_features=A_test\n",
        ")\n",
        "\n",
        "metricframe_postprocess = MetricFrame(\n",
        "    metrics=fairness_metrics,\n",
        "    y_true=y_test,\n",
        "    y_pred=postprocess_pred,\n",
        "    sensitive_features=A_test,\n",
        ")\n",
        "\n",
        "metricframe_postprocess.overall[metrics_to_report]\n",
        "\n",
        "metricframe_postprocess.difference()[metrics_to_report]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vergleichen wir nun die Leistung unseres *thresholded* Klassifikators mit dem ursprünglichen *nicht-mitigierten* Modell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "compare_metricframe_results(\n",
        "    metricframe_unmitigated,\n",
        "    metricframe_postprocess,\n",
        "    metrics=metrics_to_report,\n",
        "    names=[\"Unmitigated\", \"PostProcess\"],\n",
        ")\n",
        "\n",
        "metricframe_postprocess.by_group[metrics_to_report].plot.bar(\n",
        "    subplots=True, layout=[1, 3], figsize=[12, 4], legend=None, rot=0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wir sehen, dass der `ThresholdOptimizer`-Algorithmus eine viel geringere\n",
        "Ungleichheit zwischen den beiden Gruppen im Vergleich zum *unveränderten* Modell erreicht.\n",
        "Dies geht jedoch mit dem Nachteil einher, dass der `ThresholdOptimizer`\n",
        "eine niedrigere `balanced_accuracy`-Score für *männliche* Antragsteller erreicht.\n",
        "\n",
        "Reductions-Ansatz zur Minderung von Unfairness\n",
        "===============================================\n",
        "    \n",
        "Im vorherigen Abschnitt nahmen wir ein Fairness-unbewusstes Modell und verwendeten den\n",
        "`ThresholdOptimizer`, um die Entscheidungsgrenze des Modells zu transformieren, um\n",
        "unsere Fairness-Beschränkungen zu erfüllen. Eine wesentliche Einschränkung des\n",
        "`ThresholdOptimizer` ist die Notwendigkeit, während der Vorhersagezeit auf unser *sensibles Merkmal* zuzugreifen.\n",
        "    \n",
        "In diesem Abschnitt werden wir den *Reductions*-Ansatz von Agarwal et al.\n",
        "(2018) `agarwal2018reductions`{.interpreted-text role=\"footcite\"} verwenden, um\n",
        "Modelle zu erstellen, die die Fairness-Beschränkung erfüllen, ohne während der Bereitstellungszeit Zugriff\n",
        "auf die sensiblen Merkmale zu benötigen.\n",
        "    \n",
        "Der Hauptreduktion-Algorithmus in Fairlearn ist `ExponentiatedGradient`.\n",
        "Der Algorithmus erstellt eine Folge von neu gewichteten Datensätzen und trainiert\n",
        "den umschlossenen Klassifikator auf jedem dieser Datensätze neu. Dieser Neu-Trainingsprozess\n",
        "garantiert die Auffindung eines Modells, das die Fairness-Beschränkungen erfüllt\n",
        "und gleichzeitig die Leistungsmetrik optimiert.\n",
        "    \n",
        "Das von `ExponentiatedGradient` zurückgegebene Modell besteht aus mehreren inneren\n",
        "Modellen, die von einem umschlossenen Estimator zurückgegeben werden.\n",
        "    \n",
        "Um ein `ExponentiatedGradient`-Modell zu instanziieren, übergeben wir zwei\n",
        "Parameter:\n",
        "    \n",
        "-   einen Basis-`estimator` (Objekt, das das Training unterstützt)\n",
        "-   Fairness `constraints` (Objekt vom Typ\n",
        "    `fairlearn.reductions.Moment`{.interpreted-text role=\"class\"})\n",
        "    \n",
        "Beim Übergeben einer Fairness-*Constraint* als `Moment` können wir einen\n",
        "`epsilon`-Wert angeben, der die maximal erlaubte Differenz oder das Verhältnis\n",
        "zwischen unserem größten und kleinsten Wert darstellt. Zum Beispiel bedeutet im folgenden Code,\n",
        "`EqualizedOdds(difference_bound=epsilon)`, dass wir `EqualizedOdds` als unsere Fairness-Beschränkung verwenden und eine maximale\n",
        "Differenz von `epsilon` zwischen unserem größten und kleinsten *equalized\n",
        "odds*-Wert zulassen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_expgrad_models_per_epsilon(estimator, epsilon, X_train, y_train, A_train):\n",
        "    \"\"\"Instantiate and train an ExponentiatedGradient model on the\n",
        "    balanced training dataset.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    Estimator: Base estimator to contains a fit and predict function.\n",
        "    Epsilon: Float representing maximum difference bound for the fairness Moment constraint\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Predictors\n",
        "        List of inner model predictors learned by the ExponentiatedGradient\n",
        "        model during the training process.\n",
        "\n",
        "    \"\"\"\n",
        "    exp_grad_est = ExponentiatedGradient(\n",
        "        estimator=estimator,\n",
        "        sample_weight_name=\"classifier__sample_weight\",\n",
        "        constraints=EqualizedOdds(difference_bound=epsilon),\n",
        "    )\n",
        "    # Is this an issue - Re-runs\n",
        "    exp_grad_est.fit(X_train, y_train, sensitive_features=A_train)\n",
        "    predictors = exp_grad_est.predictors_\n",
        "    return predictors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Da der *Performance-Fairness Trade-off*, der vom `ExponentiatedGradient`-Modell gelernt wird, empfindlich auf unseren gewählten `epsilon`-Wert reagiert, können wir `epsilon` als einen *Hyperparameter* behandeln und über eine Reihe von potenziellen Werten iterieren. Hier werden wir zwei `ExponentiatedGradient`-Modelle trainieren, eines mit `epsilon=0.01` und das zweite mit `epsilon=0.02`, und die inneren Modelle, die durch jeden der Trainingsprozesse gelernt wurden, speichern.\n",
        "\n",
        "In der Praxis empfehlen wir, kleinere Werte für `epsilon` in der Größenordnung der *Quadratwurzel* der Anzahl der Stichproben im Trainingsdatensatz zu wählen:\n",
        "$\\dfrac{1}{\\sqrt{\\text{numberSamples}}} \\approx \\dfrac{1}{\\sqrt{25000}} \\approx 0.01$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "epsilons = [0.01, 0.02]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "all_models = {}\n",
        "for eps in epsilons:\n",
        "    all_models[eps] = get_expgrad_models_per_epsilon(\n",
        "        estimator=estimator,\n",
        "        epsilon=eps,\n",
        "        X_train=X_train,\n",
        "        y_train=y_train,\n",
        "        A_train=A_train,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for epsilon, models in all_models.items():\n",
        "    print(f\"For epsilon {epsilon}, ExponentiatedGradient learned {len(models)} inner models\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hier können wir alle inneren Modelle sehen, die für jeden `epsilon`-Wert gelernt wurden. Beim `ExponentiatedGradient`-Modell spezifizieren wir einen `epsilon`-Parameter, der die maximale Ungleichheit in unserer Fairness-Metrik darstellt, die unser finales Modell erfüllen sollte. Zum Beispiel bedeutet ein `epsilon=0.02`, dass der Trainingswert der *equalized odds difference* des zurückgegebenen Modells höchstens `0.02` ist (wenn der Algorithmus konvergiert).\n",
        "\n",
        "Überprüfung der inneren Modelle von ExponentiatedGradient\n",
        "==========================================================\n",
        "\n",
        "In vielen Situationen, aufgrund von Regulierung oder anderen technischen Einschränkungen, kann die zufällige Natur des `ExponentiatedGradient`-Algorithmus unerwünscht sein. Darüber hinaus führen die mehreren inneren Modelle des Algorithmus zu Herausforderungen bei der Modellinterpretierbarkeit. Eine mögliche Lösung, um diese Probleme zu vermeiden, besteht darin, eines der inneren Modelle auszuwählen und es stattdessen bereitzustellen.\n",
        "\n",
        "Im vorherigen Abschnitt haben wir mehrere `ExponentiatedGradient`-Modelle auf unterschiedlichen `epsilon`-Niveaus trainiert und alle inneren Modelle gesammelt, die durch diesen Prozess gelernt wurden. Beim Auswählen eines geeigneten inneren Modells berücksichtigen wir Trade-offs zwischen unseren beiden interessierenden Metriken: *balanced error rate* und *equalized odds difference*. Da unser Fokus auf diesen beiden Metriken liegt, werden wir die Modelle herausfiltern, die in beiden Metriken von einem anderen Modell übertroffen werden (wir bezeichnen diese als *\\\"dominierten\\\"* Modelle), und nur die verbleibenden *\\\"nicht dominierten\\\"* Modelle plotten.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def is_pareto_efficient(points):\n",
        "    \"\"\"Filter a NumPy Matrix to remove rows that are strictly dominated by\n",
        "    another row in the matrix. Strictly dominated means the all the row values\n",
        "    are greater than the values of another row.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    Points: NumPy array (NxM) of model metrics.\n",
        "        Assumption that smaller values for metrics are preferred.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Boolean Array\n",
        "        Nx1 boolean mask representing the non-dominated indices.\n",
        "    \"\"\"\n",
        "    n, m = points.shape\n",
        "    is_efficient = np.ones(n, dtype=bool)\n",
        "    for i, c in enumerate(points):\n",
        "        if is_efficient[i]:\n",
        "            is_efficient[is_efficient] = np.any(points[is_efficient] < c, axis=1)\n",
        "            is_efficient[i] = True\n",
        "    return is_efficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def filter_dominated_rows(points):\n",
        "    \"\"\"Remove rows from a DataFrame that are monotonically dominated by\n",
        "    another row in the DataFrame.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    Points: DataFrame where each row represents the summarized performance\n",
        "            (balanced accuracy, fairness metric) of an inner model.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pareto mask: Boolean mask representing indices of input DataFrame that are not monotonically dominated.\n",
        "    masked_DataFrame: DataFrame with dominated rows filtered out.\n",
        "\n",
        "    \"\"\"\n",
        "    pareto_mask = is_pareto_efficient(points.to_numpy())\n",
        "    return pareto_mask, points.loc[pareto_mask, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def aggregate_predictor_performances(predictors, metric, X_test, Y_test, A_test=None):\n",
        "    \"\"\"Compute the specified metric for all classifiers in predictors.\n",
        "    If no sensitive features are present, the metric is computed without\n",
        "    disaggregation.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    predictors: A set of classifiers to generate predictions from.\n",
        "    metric: The metric (callable) to compute for each classifier in predictor\n",
        "    X_test: The data features of the testing data set\n",
        "    Y_test: The target labels of the teting data set\n",
        "    A_test: The sensitive feature of the testing data set.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List of performance scores for each classifier in predictors, for the\n",
        "    given metric.\n",
        "    \"\"\"\n",
        "    all_predictions = [predictor.predict(X_test) for predictor in predictors]\n",
        "    if A_test is not None:\n",
        "        return [metric(Y_test, Y_sweep, sensitive_features=A_test) for Y_sweep in all_predictions]\n",
        "    else:\n",
        "        return [metric(Y_test, Y_sweep) for Y_sweep in all_predictions]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def model_performance_sweep(models_dict, X_test, y_test, A_test):\n",
        "    \"\"\"Compute the equalized_odds_difference and balanced_error_rate for a\n",
        "    given list of inner models learned by the ExponentiatedGradient algorithm.\n",
        "    Return a DataFrame containing the epsilon level of the model, the index\n",
        "    of the model, the equalized_odds_difference score and the balanced_error\n",
        "    for the model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    models_dict: Dictionary mapping model ids to a model.\n",
        "    X_test: The data features of the testing data set\n",
        "    y_test: The target labels of the testing data set\n",
        "    A_test: The sensitive feature of the testing data set.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    DataFrame where each row represents a model (epsilon, index) and its\n",
        "    performance metrics\n",
        "    \"\"\"\n",
        "    performances = []\n",
        "    for eps, models in models_dict.items():\n",
        "        eq_odds_difference = aggregate_predictor_performances(\n",
        "            models, equalized_odds_difference, X_test, y_test, A_test\n",
        "        )\n",
        "        bal_acc_score = aggregate_predictor_performances(\n",
        "            models, balanced_accuracy_score, X_test, y_test\n",
        "        )\n",
        "        for i, score in enumerate(eq_odds_difference):\n",
        "            performances.append((eps, i, score, (1 - bal_acc_score[i])))\n",
        "    performances_df = pd.DataFrame.from_records(\n",
        "        performances,\n",
        "        columns=[\"epsilon\", \"index\", \"equalized_odds\", \"balanced_error\"],\n",
        "    )\n",
        "    return performances_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "performance_df = model_performance_sweep(all_models, X_test, y_test, A_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "performance_subset = performance_df.loc[:, [\"equalized_odds\", \"balanced_error\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mask, pareto_subset = filter_dominated_rows(performance_subset)\n",
        "\n",
        "performance_df_masked = performance_df.loc[mask, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Jetzt plotten wir die Performance-Tradeoffs zwischen all unseren Modellen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for index, row in performance_df_masked.iterrows():\n",
        "    bal_error, eq_odds_diff = row[\"balanced_error\"], row[\"equalized_odds\"]\n",
        "    epsilon_, index_ = row[\"epsilon\"], row[\"index\"]\n",
        "    plt.scatter(bal_error, eq_odds_diff, color=\"green\", label=\"ExponentiatedGradient\")\n",
        "    plt.text(\n",
        "        bal_error + 0.001,\n",
        "        eq_odds_diff + 0.0001,\n",
        "        f\"Eps: {epsilon_}, Idx: {int(index_)}\",\n",
        "        fontsize=10,\n",
        "    )\n",
        "plt.scatter(\n",
        "    1.0 - balanced_accuracy_unmitigated,\n",
        "    equalized_odds_unmitigated,\n",
        "    label=\"UnmitigatedModel\",\n",
        ")\n",
        "plt.scatter(1.0 - bal_acc_postprocess, eq_odds_postprocess, label=\"PostProcess\")\n",
        "plt.xlabel(\"Weighted Error Rate\")\n",
        "plt.ylabel(\"Equalized Odds\")\n",
        "plt.legend(bbox_to_anchor=(1.85, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wir sehen, dass der `ThresholdOptimizer`-Algorithmus eine viel geringere\n",
        "Ungleichheit zwischen den beiden Gruppen im Vergleich zum *unveränderten* Modell erreicht.\n",
        "Dies geht jedoch mit dem Nachteil einher, dass der `ThresholdOptimizer`\n",
        "eine niedrigere `balanced_accuracy`-Score für *männliche* Antragsteller erreicht.\n",
        "\n",
        "Reductions-Ansatz zur Minderung von Unfairness\n",
        "===============================================\n",
        "\n",
        "Im vorherigen Abschnitt nahmen wir ein Fairness-unbewusstes Modell und verwendeten den\n",
        "`ThresholdOptimizer`, um die Entscheidungsgrenze des Modells zu transformieren, um\n",
        "unsere Fairness-Beschränkungen zu erfüllen. Eine wesentliche Einschränkung des\n",
        "`ThresholdOptimizer` ist die Notwendigkeit, während der Vorhersagezeit auf unser *sensibles Merkmal* zuzugreifen.\n",
        "\n",
        "In diesem Abschnitt werden wir den *Reductions*-Ansatz von Agarwal et al.\n",
        "(2018) `agarwal2018reductions`{.interpreted-text role=\"footcite\"} verwenden, um\n",
        "Modelle zu erstellen, die die Fairness-Beschränkung erfüllen, ohne während der Bereitstellungszeit Zugriff\n",
        "auf die sensiblen Merkmale zu benötigen.\n",
        "\n",
        "Der Hauptreduktion-Algorithmus in Fairlearn ist `ExponentiatedGradient`.\n",
        "Der Algorithmus erstellt eine Folge von neu gewichteten Datensätzen und trainiert\n",
        "den umschlossenen Klassifikator auf jedem dieser Datensätze neu. Dieser Neu-Trainingsprozess\n",
        "garantiert die Auffindung eines Modells, das die Fairness-Beschränkungen erfüllt\n",
        "und gleichzeitig die Leistungsmetrik optimiert.\n",
        "\n",
        "Das von `ExponentiatedGradient` zurückgegebene Modell besteht aus mehreren inneren\n",
        "Modellen, die von einem umschlossenen Estimator zurückgegeben werden.\n",
        "\n",
        "Um ein `ExponentiatedGradient`-Modell zu instanziieren, übergeben wir zwei\n",
        "Parameter:\n",
        "\n",
        "-   einen Basis-`estimator` (Objekt, das das Training unterstützt)\n",
        "-   Fairness `constraints` (Objekt vom Typ\n",
        "    `fairlearn.reductions.Moment`{.interpreted-text role=\"class\"})\n",
        "\n",
        "Beim Übergeben einer Fairness-*Beschränkung* als `Moment` können wir einen\n",
        "`epsilon`-Wert angeben, der die maximal erlaubte Differenz oder das Verhältnis\n",
        "zwischen unserem größten und kleinsten Wert darstellt. Zum Beispiel bedeutet im folgenden Code,\n",
        "`EqualizedOdds(difference_bound=epsilon)`, dass wir `EqualizedOdds` als unsere Fairness-Beschränkung verwenden und eine maximale\n",
        "Differenz von `epsilon` zwischen unserem größten und kleinsten *equalized\n",
        "odds*-Wert zulassen.\n",
        "\n",
        "Da der *Performance-Fairness Trade-off*, der vom `ExponentiatedGradient`-Modell gelernt wird, empfindlich auf unseren gewählten `epsilon`-Wert reagiert, können wir `epsilon` als einen *Hyperparameter* behandeln und über eine Reihe von potenziellen Werten iterieren. Hier werden wir zwei `ExponentiatedGradient`-Modelle trainieren, eines mit `epsilon=0.01` und das zweite mit `epsilon=0.02`, und die inneren Modelle, die durch jeden der Trainingsprozesse gelernt wurden, speichern.\n",
        "\n",
        "In der Praxis empfehlen wir, kleinere Werte für `epsilon` in der Größenordnung der *Quadratwurzel* der Anzahl der Stichproben im Trainingsdatensatz zu wählen:\n",
        "$\\dfrac{1}{\\sqrt{\\text{numberSamples}}} \\approx \\dfrac{1}{\\sqrt{25000}} \\approx 0.01$\n",
        "\n",
        "Hier können wir alle inneren Modelle sehen, die für jeden `epsilon`-Wert gelernt wurden. Beim `ExponentiatedGradient`-Modell spezifizieren wir einen `epsilon`-Parameter, der die maximale Ungleichheit in unserer Fairness-Metrik darstellt, die unser finales Modell erfüllen sollte. Zum Beispiel bedeutet ein `epsilon=0.02`, dass der Trainingswert der *equalized odds difference* des zurückgegebenen Modells höchstens `0.02` ist (wenn der Algorithmus konvergiert).\n",
        "\n",
        "Überprüfung der inneren Modelle von ExponentiatedGradient\n",
        "==========================================================\n",
        "\n",
        "In vielen Situationen, aufgrund von Regulierung oder anderen technischen Einschränkungen, kann die zufällige Natur des `ExponentiatedGradient`-Algorithmus unerwünscht sein. Darüber hinaus führen die mehreren inneren Modelle des Algorithmus zu Herausforderungen bei der Modellinterpretierbarkeit. Eine mögliche Lösung, um diese Probleme zu vermeiden, besteht darin, eines der inneren Modelle auszuwählen und es stattdessen bereitzustellen.\n",
        "\n",
        "Im vorherigen Abschnitt haben wir mehrere `ExponentiatedGradient`-Modelle auf unterschiedlichen `epsilon`-Niveaus trainiert und alle inneren Modelle gesammelt, die durch diesen Prozess gelernt wurden. Beim Auswählen eines geeigneten inneren Modells berücksichtigen wir Trade-offs zwischen unseren beiden interessierenden Metriken: *balanced error rate* und *equalized odds difference*. Da unser Fokus auf diesen beiden Metriken liegt, werden wir die Modelle herausfiltern, die in beiden Metriken von einem anderen Modell übertroffen werden (wir bezeichnen diese als die *\\\"dominierten\\\"* Modelle), und nur die verbleibenden *\\\"nicht dominierten\\\"* Modelle plotten.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def filter_models_by_unmitigiated_score(\n",
        "    all_models,\n",
        "    models_frames,\n",
        "    unmitigated_score,\n",
        "    performance_metric=\"balanced_error\",\n",
        "    fairness_metric=\"equalized_odds\",\n",
        "    threshold=0.01,\n",
        "):\n",
        "    \"\"\"Filter out models whose performance score is above the desired\n",
        "    threshold. Out of the remaining model, return the models with the best\n",
        "    score on the fairness metric.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    all_models: Dictionary (Epsilon, Index) mapping (epilson, index number) pairs to a Model object\n",
        "    models_frames: A DataFrame representing each model's performance and fairness score.\n",
        "    unmitigated_score: The performance score of the unmitigated model.\n",
        "    performance_metric: The model performance metric to threshold on.\n",
        "    fairness_metric: The fairness metric to optimize for\n",
        "    threshold: The threshold padding added to the :code:`unmitigated_score`.\n",
        "\n",
        "    \"\"\"\n",
        "    # Create threshold based on balanced_error of unmitigated model and filter\n",
        "    models_filtered = models_frames.query(\n",
        "        f\"{performance_metric} <= {unmitigated_score + threshold}\"\n",
        "    )\n",
        "    best_row = models_filtered.sort_values(by=[fairness_metric]).iloc[0]\n",
        "    # Choose the model with smallest equalized_odds difference\n",
        "    epsilon, index = best_row[[\"epsilon\", \"index\"]]\n",
        "    return {\n",
        "        \"model\": all_models[epsilon][index],\n",
        "        \"epsilon\": epsilon,\n",
        "        \"index\": index,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "best_model = filter_models_by_unmitigiated_score(\n",
        "    all_models,\n",
        "    models_frames=performance_df,\n",
        "    unmitigated_score=(1.0 - balanced_accuracy_unmitigated),\n",
        "    threshold=0.015,\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"Epsilon for best model: {best_model.get('epsilon')}, Index number: {best_model.get('index')}\"\n",
        ")\n",
        "inprocess_model = best_model.get(\"model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Jetzt haben wir unser bestes inneres Modell ausgewählt, lassen Sie uns die Vorhersagen des Modells auf dem Testdatensatz sammeln und die relevanten Leistungsmetriken berechnen.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y_pred_inprocess = inprocess_model.predict(X_test)\n",
        "\n",
        "bal_acc_inprocess = balanced_accuracy_score(y_test, y_pred_inprocess)\n",
        "eq_odds_inprocess = equalized_odds_difference(y_test, y_pred_inprocess, sensitive_features=A_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "metricframe_inprocess = MetricFrame(\n",
        "    metrics=fairness_metrics,\n",
        "    y_true=y_test,\n",
        "    y_pred=y_pred_inprocess,\n",
        "    sensitive_features=A_test,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "metricframe_inprocess.difference()[metrics_to_report]\n",
        "\n",
        "metricframe_inprocess.overall[metrics_to_report]\n",
        "\n",
        "metricframe_inprocess.by_group[metrics_to_report].plot.bar(\n",
        "    subplots=True, layout=[1, 3], figsize=[12, 4], legend=None, rot=0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Diskussion der Performance und des Trade-Offs\n",
        "======================================\n",
        "\n",
        "Jetzt haben wir zwei verschiedene Fairness-aware Modelle mithilfe des *Postprocessing*-Ansatzes und des *Reductions*-Ansatzes trainiert. Lassen Sie uns die Leistung dieser Modelle mit unserem ursprünglichen Fairness-unbewussten Modell vergleichen.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "metric_error_pairs = [\n",
        "    (\"balanced_accuracy\", \"balanced_acc_error\"),\n",
        "    (\"false_positive_rate\", \"false_positive_error\"),\n",
        "    (\"false_negative_rate\", \"false_negative_error\"),\n",
        "]\n",
        "\n",
        "\n",
        "def create_metricframe_w_errors(mframe, metrics_to_report, metric_error_pair):\n",
        "    mframe_by_group = mframe.by_group.copy()\n",
        "    for metric_name, error_name in metric_error_pair:\n",
        "        mframe_by_group[metric_name] = mframe_by_group[metric_name].apply(lambda x: f\"{x:.3f}\")\n",
        "        mframe_by_group[error_name] = mframe_by_group[error_name].apply(lambda x: f\"{x:.3f}\")\n",
        "        mframe_by_group[metric_name] = mframe_by_group[metric_name].str.cat(\n",
        "            mframe_by_group[error_name], sep=\"±\"\n",
        "        )\n",
        "    return mframe_by_group[metrics_to_report]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bericht über Modell Performance und Fehlerbalken für Metriken\n",
        "=========================================================\n",
        "\n",
        "**Unverändertes Modell**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "create_metricframe_w_errors(metricframe_unmitigated, metrics_to_report, metric_error_pairs)\n",
        "\n",
        "metricframe_unmitigated.overall[metrics_to_report]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**ExponentiatedGradient Modell**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "create_metricframe_w_errors(metricframe_inprocess, metrics_to_report, metric_error_pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**ThresholdOptimizer**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "metricframe_inprocess.overall[metrics_to_report]\n",
        "\n",
        "create_metricframe_w_errors(metricframe_postprocess, metrics_to_report, metric_error_pairs)\n",
        "\n",
        "metricframe_postprocess.overall[metrics_to_report]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see both of our fairness-aware models yield a slight decrease in the\n",
        "*balanced\\_accuracy* for *male applicants* compared to our\n",
        "fairness-unaware model. In the *reductions* model, we see a decrease in\n",
        "the *false positive rate* for *female applicants*. This is accompanied\n",
        "by an increase in the *false negative rate* for *male applicants*.\n",
        "However overall, the *equalized odds difference* for the *reductions*\n",
        "models is lower than that of the original fairness-unaware model.\n",
        "\n",
        "Conclusion and Discussion\n",
        "Wir sehen, dass beide unserer Fairness-aware Modelle eine leichte Abnahme der *balanced_accuracy* für *männliche Antragsteller* im Vergleich zu unserem Fairness-unbewussten Modell aufweisen. Im *Reductions*-Modell beobachten wir eine Abnahme der *false positive rate* für *weibliche Antragsteller*. Dies geht einher mit einer Zunahme der *false negative rate* für *männliche Antragsteller*. Insgesamt ist jedoch die *equalized odds difference* für die *Reductions*-Modelle niedriger als die des ursprünglichen Fairness-unbewussten Modells.\n",
        "\n",
        "Fazit und Diskussion\n",
        "====================\n",
        "\n",
        "In dieser Fallstudie haben wir den Prozess der Bewertung eines Kreditentscheidungsmodells auf geschlechtsbezogene Leistungsunterschiede durchlaufen. Unsere Analyse folgt eng der Arbeit, die in dem Microsoft/EY Whitepaper `dudik2020assessing`{.interpreted-text role=\"footcite\"} durchgeführt wurde, wo sie das *Fairlearn*-Toolkit verwendeten, um ein Fairness-unbewusstes baumbasiertes Modell zu auditieren. Wir haben *Postprocessing*- und *Reductions*-Minderungs-Techniken angewendet, um die *equalized odds difference* in unserem Modell zu mindern.\n",
        "\n",
        "Durch den *Reductions*-Prozess haben wir ein Modell erstellt, das die *equalized odds difference* des ursprünglichen Modells reduziert, ohne eine drastische Erhöhung der *balanced error score*. Wenn dies ein echtes Modell wäre, das von einem Finanzinstitut entwickelt wird, würde die *balanced error score* eine Annäherung an die Rentabilität des Modells darstellen. Indem wir eine relativ ähnliche *balanced error score* beibehalten haben, haben wir ein Modell produziert, das die Rentabilität für das Unternehmen erhält und gleichzeitig fairere und gerechtere Ergebnisse für Frauen in diesem Szenario liefert.\n",
        "\n",
        "\n",
        "References\n",
        "==========\n",
        "\n",
        "::: {.footbibliography}\n",
        ":::\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aufgaben\n",
        "========================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. **Pre-Processing Ansätze ausprobieren**\n",
        "- **Beispiele für Techniken:**\n",
        "  - **Reweighing:** Anpassung der Gewichtungen der Datenpunkte, um Ungleichgewichte in den sensiblen Merkmalen auszugleichen.\n",
        "  - **Disparate Impact Remover:** Transformation der Daten, um den Einfluss sensibler Merkmale auf die Zielvariable zu reduzieren.\n",
        "- **Aufgabe:** Wende eine Pre-Processing Methode an und bewerte deren Einfluss auf die Fairness- und Performance-Metriken des Modells.\n",
        "(https://github.com/Trusted-AI/AIF360/blob/main/examples/tutorial_credit_scoring.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. **Untersuchung und Visualisierung zusätzlicher Biases im Datensatz**\n",
        "- **Aufgabe:** \n",
        "  - Erstelle Visualisierungen (z.B. Histogramme, Boxplots) zur Analyse der Verteilung verschiedener Merkmale in Bezug auf das sensitive Merkmal `SEX` und das Ziellabel `default`.\n",
        "  - Identifiziere mögliche Korrelationen oder Muster, die auf weitere Fairness-Herausforderungen hinweisen könnten.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. **Vergleich verschiedener Fairness-Metriken**\n",
        "- **Beispiele für Fairness-Metriken:**\n",
        "  - **Demographic Parity (Demografische Parität)**\n",
        "  - **Equal Opportunity (Gleiche Chancen)**\n",
        "  - **Predictive Parity (Vorhersageparität)**\n",
        "- **Aufgabe:** \n",
        "  - Berechne verschiedene Fairness-Metriken für die trainierten Modelle.\n",
        "  - Diskutiere, wie sich die Wahl der Metrik auf die Bewertung der Modellfairness auswirkt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
